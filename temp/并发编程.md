sudo -u admin /opt/ifeve/java/bin/jstack 31177 > /home/tengfei.fangtf/dump17

grep java.lang.Thread.State dump17 | awk '{print $2$3$4$5}'| sort | uniq -c

熟练使用jmap、jstack、jconsole



性能角度：

1. 通过单机多机提升性能
2. 考虑机器资源限制



JAVA未使用PV，而是封装了monitor， monitor是基于PV的OO封装，减少出错几率？

https://blog.csdn.net/Dylan_Frank/article/details/79929567     底层

https://blog.csdn.net/Dylan_Frank/article/details/79965871     

https://blog.csdn.net/Dylan_Frank/article/details/79982752 管程

https://www.cnblogs.com/Brake/p/Operating_System_Monitor.html

https://www.cnblogs.com/alinh/p/6905221.html 这个讲的是锁和同步  锁可以看做二元semophore，我理解就是semophore的特例，本质没有什么不同，但是底层另外进行了新的实现。



https://www.jianshu.com/p/6fe4bc3374a2 java管程 

https://www.jianshu.com/p/f83ae055b6aa java lock和retreetlock

https://www.jianshu.com/p/82bdd60ff816  java多线程 Conditon



http://www.xuetangx.com/courses/course-v1:TsinghuaX+30240243X+sp/about 操作系统的学堂在线



condition，既然PV原语实现了生产者消费者，那么



java thread的blocked和waiting的区别：

https://blog.csdn.net/teaey/article/details/20059129

When a thread calls Object.wait method, it releases all the acquired monitors and is put into WAITING (or TIMED_WAITING if we call the timeout versions of the waitmethod) state. Now when the thread is notified either by notify() or bynotifyAll() call on the same object then the waiting state of the thread ends and the thread starts attempting to regain all the monitors which it had acquired at the time ofwait call. At one time there may be several threads trying to regain (or maybe gain for the first time) their monitors. If more than one threads attempt to acquire the monitor of a particular object then only one thread (selected by the JVM scheduler) is granted the monitor and all other threads are put into BLOCKED state. Got the difference? 

临界区是只有window下才有的数据结构。

在底层基础上，应用于不同场景，有同步的ECF semophore、锁、condition，再高一层的封装有monitor





| 操作系统 | 创建               | 加锁                | 解锁                 | 销毁                  |
| -------- | ------------------ | ------------------- | -------------------- | --------------------- |
| Win32    | CreateMutex        | WaitForSingleObject | ReleaseMutex         | CloseHandle           |
| Linux    | pthread_mutex_init | pthread_mutex_lock  | pthread_mutex_unlock | pthread_mutex_destroy |
| Solaris  | mutex_init         | mutex_lock          | mutex_unlock         | mutex_destroy         |

管程由四部分组成：

1.管程内部的共享变量。 

2.管程内部的条件变量。

3.管程内部并行执行的进程。

4.对于局部与管程内部的共享数据设置初始值的语句。  



#### 调度GreenThread

https://en.wikipedia.org/wiki/Green_threads

In [Java 1.1](https://en.wikipedia.org/wiki/Java_1.1), green threads were the only threading model used by the JVM,[[9\]](https://en.wikipedia.org/wiki/Green_threads#cite_note-9) at least on [Solaris](https://en.wikipedia.org/wiki/Solaris_(operating_system)). As green threads have some limitations compared to native threads, subsequent Java versions dropped them in favor of native threads.[[10\]](https://en.wikipedia.org/wiki/Green_threads#cite_note-sco-10)[[11\]](https://en.wikipedia.org/wiki/Green_threads#cite_note-11) 

已经抛弃了。







##原子操作：

这里就是cpu内存底层的知识了。

CPU 内存、缓存图， 总线锁和缓存锁，这是当今多核CPU必备知识。这是一个本质和抽象关系



CAS,compare and swap CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。 如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值 。否则，处理器不做任何操作。 



CPU的CAS指令 

java.util.concurrent包完全建立在CAS之上的 





### JAVA内存模型

- JM内存模型类似于多核CPU
- 重排序，重排序有编译器重排序、指令级并行重排序、内存系统重排序，重排序会导致可见性问题。对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排
  序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM的处理器重排序规则会要
  求Java编译器在生成指令序列时，插入特定类型的内存屏障（Memory Barriers，Intel称之为
  Memory Fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序。
- JMM用内存屏障保证顺序，LoadLoadBarier、StoreStoreBarier、LoadStoreBarier、StoreLoadBarier
- 与程序员密切相关的happens-before规则如下。
  ·程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。
  ·监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。
  ·volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的
  读。
  ·传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。
- as-if-serial语义的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）
  程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。



####顺序一致性

1）一个线程中的所有操作必须按照程序的顺序来执行。
2）（不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内
存模型中，每个操作都必须原子执行且立刻对所有线程可见。



### 锁相关知识





学习这块需要明确抽象与实现的关系，对于锁，和操作系统中概念是一样的，有Lock、Semaphore、Condition等几种概念，并且有管程、









Lock: RentrantLock\ReentrantReadWriteLock    Semaphore   Condition

------------------------------------------------------------------------------------

AbstractQueuedSynchronizer   -- ConditionObject                                                       

---------------------------------------

Unsafe： CAS     Park       



语言级的设计synchronizer wait notify这是语言级的设计，因为和面向对象紧密的集合在一起了。



#### unsafe

Java无法直接访问底层操作系统，而是通过本地（native）方法来访问。不过尽管如此，JVM还是开了一个后门，JDK中有一个类Unsafe，它提供了硬件级别的**原子操作** 这个类尽管里面的方法都是public的，但是并没有办法使用它们，JDK API文档也没有提供任何关于这个类的方法的解释。总而言之，对于Unsafe类的使用都是受限制的，只有授信的代码才能获得该类的实例，当然JDK库里面的类是可以随意使用的。 

```
compareAndSwapInt CPU指令
```

通过该指令可以设计轻量级自旋锁，并且该设计是针对多核设计，如果是单核，有没有该设计都一样。所以后面理解这些东西的时候，都需要按照多核来理解。



#### LockSupport

简而言之，这里就是讲线程阻塞掉

- ```
  park: Disables the current thread for thread scheduling purposes unless the
  permit is available if the thread is interupt\unpark 
  ```

- ```
  unpark:Makes available the permit for the given thread, if it
   was not already available
  ```

















































#### condition

condition和c中cond语义一样， Condition



















### AbstractQueuedSynchronizer

(1) Node是个静态内部类：

**静态内部类**

1、只有内部类才能声明为static，也可以说是静态内部类 
2、只有静态内部类才能拥有静态成员，普通内部类只能定义普通成员 
3、静态类跟静态方法一样，只能访问其外部类的静态成员 
4、如果在外部类的静态方法中访问内部类，这时候只能访问静态内部类



Node数据结构：

```
*   SIGNAL:     The successor of this node is (or will soon be)
*               blocked (via park), so the current node must
*               unpark its successor when it releases or
*               cancels. To avoid races, acquire methods must
*               first indicate they need a signal,
*               then retry the atomic acquire, and then,
*               on failure, block.
*   CANCELLED:  This node is cancelled due to timeout or interrupt.
*               Nodes never leave this state. In particular,
*               a thread with cancelled node never again blocks.
*   CONDITION:  This node is currently on a condition queue.
*               It will not be used as a sync queue node
*               until transferred, at which time the status
*               will be set to 0. (Use of this value here has
*               nothing to do with the other uses of the
*               field, but simplifies mechanics.)
*   PROPAGATE:  A releaseShared should be propagated to other
*               nodes. This is set (for head node only) in
*               doReleaseShared to ensure propagation
*               continues, even if other operations have
*               since intervened.
```





这个类 是 Doug Lea作为Lock\Semophore\CoutDownLauch等的实现基础，使用这个类，进行了各种抽象。



- ```
  Subclasses should be defined as non-public internal helper
  classes that are used to implement the synchronization properties
  of their enclosing class
  可以看到各种抽象实现都有一个内部类syn继承这个类
  ```

- `This class supports either or both a default <em>exclusive</em>* mode and a <em>shared</em> mode. When acquired in exclusive mode,* attempted acquires by other threads cannot succeed. Shared mode* acquires by multiple threads may (but need not) succeed`

- `This class defines a nested {@link ConditionObject} class that* can be used as a {@link Condition} implementation by subclasses* supporting exclusive mode`

- ```
  To use this class as the basis of a synchronizer, redefine the following methods
  - tryAcquire
  - tryRelease
  - tryAcquireShared
  - tryReleaseShared
  - isHeldExclusively
  ```

- CLH锁即Craig, Landin, and Hagersten (CLH) locks，CLH锁是一个自旋锁，能确保无饥饿性，提供先来先服务的公平性。

  CLH锁也是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，它不断轮询前驱的状态，如果发现前驱释放了锁就结束自旋。

- ```
  A
  * "status" field in each node keeps track of whether a thread
  * should block.  A node is signalled when its predecessor
  * releases.
  ```



20181024 这个源码研究了好几天，不好理解就是因为Queue + AWS/Park + state，三者叠加增加了复杂度，对于AWS/Park可以进行抽象理解，对于sate，state的状态变化如果理解不清楚，就真的不好理解。

从这次阅读的经验看，当出现算法上叠加，代码复杂度指数上升的情况下，我们应当把数

锁中有一堆概念：公平锁、非公平锁、独占锁、共享锁、读锁、写锁、condition等，把这些概念搞清楚相当不容易。



20181025

通过实践发现如下事实：对于算法，搞清楚基本的要素后，接着重要的就是去让其运转起来，搞清楚怎么运转的。我通过ReetrantLock为例, 说明考虑思考过程不能使用线性的思考方式，而必须使用时序的思考方式，例如下面

aquireQueued，一个for循环，代码在这里由于线程调度，停止运行。

Lock操作，如果没有获取lock，则一直代码一直停滞在lock代码中，业务逻辑代码并没有运行



- 算法部分节点入队出对和底层部分CAS、park部分是结 合在一起的。 

1. node(waitstate = -1, thread = null) -> node(waitstate = 0, thread = thread_1)     第一个节点根本不入队，这是个优化，然后第二个节点入队，创建两个节点，头结点的指向thread为null，这样就避免了如果只有一个线程情况下的出队入队。

2. node(waitstate = -1) -> node(waitstate = -1) -> node(waitstate = 0)

   

节点都进入的是park的状态,park状态的锁跑在 lock的代码段中，如下：

```
    public final void acquire(int arg) {
        if (!tryAcquire(arg) &&
            acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // 添加节点在addwaiter
            selfInterrupt();
    }
```





```
for (;;) {    // 恢复后代码又在这里运行，这里是种递归的运行方式， node就是每一个新节点，这里有点玄				妙， release后唤醒的必然是head的后继节点， 这时会在这里更新头节点，或者说进行节点 
                 的删除操作，然后lock的代码退出，进入业务逻辑代码
                
                final Node p = node.predecessor();
                if (p == head && tryAcquire(arg)) {   # 2. 有可能需要重新加锁
                    setHead(node);
                    p.next = null; // help GC
                    failed = false;
                    return interrupted;
                }
                if (shouldParkAfterFailedAcquire(p, node) &&
                    parkAndCheckInterrupt())    # 1. park后代码该线程运行就在这里停止了
                    interrupted = true;
            }
```



     ```
    public final boolean release(int arg) {
        if (tryRelease(arg)) {
            Node h = head;
            if (h != null && h.waitStatus != 0)
                unparkSuccessor(h);   // release操作的时候会释放后继节点，让后继节点运行起来
            return true;
        }
        return false;
    }
     ```



- 业务逻辑和控制逻辑，这里主要是状态

  AQS中的state，state为0，表示可以获取锁，为1，表示不可以，需要进行tryacquire的操作

  Node中有waitstate，如果wiatestate = -1，则头节点释放，需要激活后续节点，这个state是起控制作用的



- 语义

  - 公平锁和非公平锁 

    ```
            final void lock() {
                if (compareAndSetState(0, 1))   //  非公平锁，如果发现可以占用锁，就马上占用锁
                    setExclusiveOwnerThread(Thread.currentThread());
                else
                    acquire(1);
            }
    ```

  - 可重入锁

    多次加锁，state+1，释放必须释放相同的次数

  - readlock writelock

    readlock和writelock都使用的是同一个syn，对于writelock都有独占标识。

    共享锁关键算法代码

    ```
    private void doAcquireShared(int arg) {
            final Node node = addWaiter(Node.SHARED);
            boolean failed = true;
            try {
                boolean interrupted = false;
                for (;;) {
                    final Node p = node.predecessor();
                    if (p == head) {
                        int r = tryAcquireShared(arg);
                        if (r >= 0) {
                            setHeadAndPropagate(node, r); # 在这里
                            p.next = null; // help GC
                            if (interrupted)
                                selfInterrupt();
                            failed = false;
                            return;
                        }
                    }
                    if (shouldParkAfterFailedAcquire(p, node) &&
                        parkAndCheckInterrupt())   # 1. 执行了park
                        interrupted = true;
                }
            } finally {
                if (failed)
                    cancelAcquire(node);
            }
        }
        
        
        private void setHeadAndPropagate(Node node, long propagate) {
            Node h = head; // Record old head for check below
            setHead(node);   #删除头节点
            if (propagate > 0 || h == null || h.waitStatus < 0 ||
                (h = head) == null || h.waitStatus < 0) {
                Node s = node.next;
                if (s == null || s.isShared())
                    doReleaseShared();
            }
        }
    ```

    

    队列处理的时候，如果是读锁，和上述RetreenLock是一样的，当unlock时，后继节点被打开，更新掉头，如果发现这个事共享锁，则会有for循环，打开所有的共享节点，

    1. node(waitstate = -1, Exclusive) ->  node(waitstate = -1, Shared)

       -> node(waitstate = -1, Shared) -> node(waitstate = -1, Shared)-> node(waitstate = 0, Exclusive)

       如图，初始队列如上，第一个节点是独占的，则后续节点都park

    2. 第一个节点unlock，唤醒后继节点，后继节点是share的，则在不断循环setHeadAndPropagate(node, r)，只要发现跟的节点是share的，则全部打开，直到发现是独占节点。

    3. 最后一个独占节点还是要靠前驱节点unpark打开

    

    

    

    

    

    

    

- Condition

​      如果没有调用lock，则会在如下地方异常，这里就是说conditon操作必须是独占线程中操作

```
            if (Thread.currentThread() != getExclusiveOwnerThread())
                throw new IllegalMonitorStateException();
```

​     

Queue + waiterQueue:

Queue: nil and lock

waiterQueue:   (Node, state = -2, Exclusive) -> (Node, state = -2, Exclusive)  and waiter



Queue: node(waitstate = -1, thread = null) -> node(waitstate = 0, thread = thread_1) 

waiterQueue:  (Node, state = -2, Exclusive)  and waiter and signal



Queue: node(waitstate = 0, thread = null)  and unlock

waiterQueue:  (Node, state = -2, Exclusive)  and waiter



这里有个队列信息转移，如果收到signal信号，则把队列节点从wiaterQueue转移到queue中

锁住的点：

```
public final void awaitUninterruptibly() {
            Node node = addConditionWaiter();
            int savedState = fullyRelease(node);
            boolean interrupted = false;
            while (!isOnSyncQueue(node)) {  
                LockSupport.park(this);
                if (Thread.interrupted())
                    interrupted = true;
            }
```

然后unlock的时候取释放锁，继续运行，从上述锁住店点退出



































- CountDownLanch

  队列样式

  算法队列

  Queue的 state被设置为CountDownLanch的初始化值

  node(waitstate = -1, thread = null) -> node(waitstate = 0, thread = thread_1) 

  主线程await调用park被暂停调度，队列结构如上，只有2个节点。



​        每次countDown()的时候，每次countDown()的时候进行tryRelease操作，在release的时候讲state减1，但是只有state = 0的时候头结点才会释放，并将后续节点解锁。

​        

- Semaphore

  假定Semaphore被初始化为2，有4个线程，则状态如下

  Queue(state = 2) : node(waitesate = 0, thread = null)

  Queue(state = 1): node(waitesate = 0, thread = null)     and thread0 running

  Queue(state = 0): node(waitesate = 0, thread = null)     and thread0 thread1 running

  Queue(state = 0) : node(waitesate = -1, thread = null) ->  node(waitesate = -1, thread = thread2) ->  

  ​                     node(waitesate = 0, thread = thread3) and thread0 thread1 running

  then: thread0 or thread1 release:

  Queue(state = 1) : node(waitesate = -1, thread = null) ->  node(waitesate = -1, thread = thread2) ->  

  ​             node(waitesate = 0, thread = thread3)    and thread1 running  and thread0 is finished

  Queue(state = 0) : node(waitesate = -1, thread = null) ->  node(waitesate = 0, thread = thread3)   : 

  ​              and thread2 thread1 is running

  Queue(state = 1) : node(waitesate = -1, thread = null) ->  node(waitesate = 0, thread = thread3)   : 

  ​              and thread2 is running and thread1 is finished

  Queue(state = 0) : node(waitesate = 0, thread = null): and thread2  thread3 is running 

  Queue(state = 1) : node(waitesate = 0, thread = null): and   thread3 is running 

  Queue(state = 2) : node(waitesate = 0, thread = null)

  

  state变量在这里起到了控制作用，控制了同一个时间运行的线程数量，如果semophore初始化为1，则和lock作用相同。

  

  

  

  

  

  































###atomic class

#### atomic 基本类型类

- ```
  AtomicBoolean
  ```

- ```
  AtomicInteger
  ```

#### 更新数组

- `AtomicIntegerArray`

- ```
  AtomicLongArray
  ```

- ```
  AtomicReferenceArray
  ```

#### 字段类型更新

- ```
  AtomicIntegerFieldUpdater
  ```

- ```
  AtomicLongFieldUpdater
  ```

- ```
  AtomicReferenceFieldUpdater
  ```





### 容器

有三类容器:

Concurrent

copyonwrite

blockqueue





###ConcurrentHashMap



采用锁分段技术提高效率？？

插入是用到了SAW和sychronizer



get操作全程都没有加锁操作，使用了valitile的特性，说明还没有理解valitile







#### Queue

ConcurrentLinkedQueue 和LinkedBlockingQueue之间有什么差别，各用于什么场景，各有什么优劣？







###copyonwrite

#### CopyOnWriteArrayList

```
public E set(int index, E element) {
        final ReentrantLock lock = this.lock;
        lock.lock();
        try {
            Object[] elements = getArray();
            E oldValue = get(elements, index);

            if (oldValue != element) {
                int len = elements.length;
                Object[] newElements = Arrays.copyOf(elements, len);
                newElements[index] = element;
                setArray(newElements);
            } else {
                // Not quite a no-op; ensures volatile write semantics
                setArray(elements);
            }
            return oldValue;
        } finally {
            lock.unlock();
        }
    }
```

put 和 add的时候如果要添加，则copy一份数据出来，添加后将源数据指向数据



场景：用在有多个线程同时会修改一个list，且修改的次数要比读取的次数少的多的多的时候，比如很长时间偶尔会修改一次数据 





### BlockQueue

blockQueue有非常多的应用，在用到blockqueue的时候，有一种

























### ThreadPool框架

背景：

线程高效应用，不用每次都创建销毁，这是生命周期的管理。



使用：

![img](file:/../introducetoalgorithm/threadpool.png)





关键数据看到：

关键数据结构有：blockedqueue作为消息队列，set放worker



```
/**
 * The queue used for holding tasks and handing off to worker
 * threads.  
 */
private final BlockingQueue<Runnable> workQueue;

/**
 * Lock held on access to workers set and related bookkeeping.
 */
private final ReentrantLock mainLock = new ReentrantLock();

/**
 * Set containing all worker threads in pool. Accessed only when
 * holding mainLock.
 */
private final HashSet<Worker> workers = new HashSet<Worker>();

/**
 * Wait condition to support awaitTermination
 */
private final Condition termination = mainLock.newCondition();

/**
 * Tracks largest attained pool size. Accessed only under
 * mainLock.
 */
private int largestPoolSize;



/*
 * All user control parameters are declared as volatiles so that
 * ongoing actions are based on freshest values, but without need
 * for locking, since no internal invariants depend on them
 * changing synchronously with respect to other actions.
 */

/**
 * Handler called when saturated or shutdown in execute.
 */
private volatile RejectedExecutionHandler handler;

/**
 * Timeout in nanoseconds for idle threads waiting for work.
 * Threads use this timeout when there are more than corePoolSize
 * present or if allowCoreThreadTimeOut. Otherwise they wait
 * forever for new work.
 */
private volatile long keepAliveTime;
```





关键操作：

excute执行 runnable方法

submit提交future，返回一个future

shutdown关闭线程池



注意：

- 避免任务堆积
- 避免过渡扩展线程
- 线程泄露
- 避免死锁
- 避免使用ThreadLocal





##### 实现  java36讲中21讲讲解的非常透彻

Excutor的实现设计和concurrent lock一样，都是一个通用框架，上面架设不同的场景的应用类



Excutor的类图：

​	。。。

通过类图可以看到，一共有三种：

- ThreadPoolExecutor
- ScheduledThreadPoolExecutor，继承与ThreadPoolExecutor，增加了超时时间
- ForkJoinPool ?



Executor的类型，可以在Excutors类中查看：

- ```
      public static ExecutorService newCachedThreadPool() {
          return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                        60L, TimeUnit.SECONDS,
                                        new SynchronousQueue<Runnable>());
      }
      这种情况，worker是大小不限制，但是超过60秒不用就会释放掉，占用资源少，
      SynchronousQueue的意义何在？ 线程是不断扩张的
  ```

- ```
      public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) {
          return new ThreadPoolExecutor(nThreads, nThreads,
                                        0L, TimeUnit.MILLISECONDS,
                                        new LinkedBlockingQueue<Runnable>(),
                                        threadFactory);
      }
      // 线程数固定，但是消息队列无线
  ```

- ```
      public static ScheduledExecutorService newScheduledThreadPool(
              int corePoolSize, ThreadFactory threadFactory) {
          return new ScheduledThreadPoolExecutor(corePoolSize, threadFactory);
      }
  ```

- ```
      public static ExecutorService newSingleThreadExecutor() {
          return new FinalizableDelegatedExecutorService
              (new ThreadPoolExecutor(1, 1,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue<Runnable>()));
      } // 保持事件执行的顺序性
  ```

- ```
      public static ExecutorService newWorkStealingPool() {
          return new ForkJoinPool
              (Runtime.getRuntime().availableProcessors(),
               ForkJoinPool.defaultForkJoinWorkerThreadFactory,
               null, true);
      } // 重点在并发
  ```

  发现还没有搞明白 ForkJoinPool SynchronousQueue ScheduledThreadPoolExecutor

所以尽量少用Excutors，这样有助于搞清楚使用线程池



配置：

计算，CPU密集型线程池：配置Ncpu+1

等待较多的， IO密集型线程池：配置多的线程 CPU核(1 + 平均等待事件/平均工作时间)

不同的情况需要合理的拆分线程池

优先级高的任务用priorityQueue处理

使用有界队列处理，避免队列长度过大







--------------------------

线程组ThreadGroup可以见： https://www.cnblogs.com/yiwangzhibujian/p/6212104.html



----------------------

FutureTask 1.5

理解这块东西首先要把ThreadPool的框架放在心中，框架实现了相关的东西，对于同步如Future等，都是通过对于task的封装搞定的。



是一个微缩版本的AQS，读懂了AQS，再读TutureTask不难。通过阅读源码，明白了Future的关键就是FutureTask的实现： 需要get方法配合

仍然是算法、线程和状态控制

- waiter队列, 如果线程未执行完，则调用get的线程将进入waiter队列，阻塞，当线程执行完或者异常，则会给waiter队列解锁

  例如说如果有N个线程来get，则这N个线程会加入到waiter队列中

- 如果线程未执行完，则调用get的线程将进入waiter队列，阻塞，当线程执行完或者异常，则会给waiter队列解锁

- ```
      private volatile int state;
      private static final int NEW          = 0;
      private static final int COMPLETING   = 1;
      private static final int NORMAL       = 2;
      private static final int EXCEPTIONAL  = 3;
      private static final int CANCELLED    = 4;
      private static final int INTERRUPTING = 5;
      private static final int INTERRUPTED  = 6;
  ```

  通过state来控制运行，状态修改是使用CAS来进行保证原子性

​                 New   



关键代码：

```
for (WaitNode q; (q = waiters) != null;) {
            if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) {
                for (;;) {    // 将所有的park线程解锁
                    Thread t = q.thread;
                    if (t != null) {
                        q.thread = null;
                        LockSupport.unpark(t);
                    }
                    WaitNode next = q.next;
                    if (next == null)
                        break;
                    q.next = null; // unlink to help gc
                    q = next;
                }
                break;
            }
        }

        done();

        callable = null;        // to reduce footprint
    }
    
    private int awaitDone(boolean timed, long nanos)
        throws InterruptedException {
        final long deadline = timed ? System.nanoTime() + nanos : 0L;
        WaitNode q = null;
        boolean queued = false;
        for (;;) { 
            if (Thread.interrupted()) {
                removeWaiter(q);
                throw new InterruptedException();
            }

            int s = state;
            if (s > COMPLETING) {
                if (q != null)
                    q.thread = null;
                return s;
            }
            else if (s == COMPLETING) // cannot time out yet
                Thread.yield();
            else if (q == null)
                q = new WaitNode();    // for循环搞定逻辑的代码在Concurrent中比比皆是
            else if (!queued)
                queued = UNSAFE.compareAndSwapObject(this, waitersOffset,
                                                     q.next = waiters, q);
            else if (timed) {
                nanos = deadline - System.nanoTime();
                if (nanos <= 0L) {
                    removeWaiter(q);
                    return state;
                }
                LockSupport.parkNanos(this, nanos);   // 关键就是这里的park操作
            }
            else
                LockSupport.park(this);
        }
    }

```

​                                       

-------------------------------------

ForkJoinTask (1.7) ---- RecursiveTask (1.7)---- RecursiveAction(1.8) -- CountedCompleter(1.8)



运行ForkJoinTask的是  ForkJoinWorkerThread， 这种Thread中存放的是：

ForkJoinPool.WorkQueue workQueue



ForkJoinPool和在框架上和上面有所不同，这里并没有专门的set<work>队列，而是直接使用ForkJoinWorkerThread，使用了几个数字来控制的，默认是8.



而且每个ForkJoinWorkerThread都有一个队列，当空闲的时候，使用work-steal算法来窃取其它thread的线程来执行。



ForkJoinPoll中有WorkQueue[] workQueues; 每个ForkJoinWorkerThread把自己的WorkQueue注册在此

而WorkQueue中有个ForkJoinTask<?>[] array;用来存储具体的ForkJoinTask，每个ForkJoinWorkerThread从头部取ForkJoinTask执行，问题在于这些Future之间有await和signal，如何把await状态的现场放入队列？



- ForkJoinTask的关键在于fork和join，这里使用了递归的思想，因此比较难看懂

  ```
      public final ForkJoinTask<V> fork() {
          Thread t;
          if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread)
              ((ForkJoinWorkerThread)t).workQueue.push(this);
          else
              ForkJoinPool.common.externalPush(this);
          return this;
      }
  ```

  Fork干的活就是把自身加入到workQueue中，push的时候就取创建线程，这里算法的关键是怎么均匀的把任务放入到各个线程中以及窃取算法。

  ```
      private int doJoin() {
          int s; Thread t; ForkJoinWorkerThread wt; ForkJoinPool.WorkQueue w;
          return (s = status) < 0 ? s :
              ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) ?
              (w = (wt = (ForkJoinWorkerThread)t).workQueue).
              tryUnpush(this) && (s = doExec()) < 0 ? s :
              wt.pool.awaitJoin(w, this) :
              externalAwaitDone();
      }
  ```

  关键在于Join，Join干的活就是DoExec，这个工作是在await之前，因此递归执行，关键数据结构就是Queue





--------------------------------

ScheduledThreadPoolExcutor 是在ThreadPoolExcutor上的增强，增加调度能力。

每次run的时候便增加一个任务到队列中。



```
public void run() {
    boolean periodic = isPeriodic();
    if (!canRunInCurrentRunState(periodic))
        cancel(false);
    else if (!periodic)
        ScheduledFutureTask.super.run();
    else if (ScheduledFutureTask.super.runAndReset()) {
        setNextRunTime();
        reExecutePeriodic(outerTask);
    }
}

    void reExecutePeriodic(RunnableScheduledFuture<?> task) {
        if (canRunInCurrentRunState(true)) {
            super.getQueue().add(task);
            if (!canRunInCurrentRunState(true) && remove(task))
                task.cancel(false);
            else
                ensurePrestart();
        }
    }
```



定时的执行时DelayQueue完成的

```
public RunnableScheduledFuture<?> take() throws InterruptedException {
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        for (;;) {
            RunnableScheduledFuture<?> first = queue[0]; #取第0个task
            if (first == null)
                available.await();
            else {
                long delay = first.getDelay(NANOSECONDS); #获取延时时间
                if (delay <= 0)
                    return finishPoll(first);
                first = null; // don't retain ref while waiting
                if (leader != null)
                    available.await();
                else {
                    Thread thisThread = Thread.currentThread();
                    leader = thisThread;
                    try {
                        available.awaitNanos(delay); #调用cond的等待
                    } finally {
                        if (leader == thisThread)
                            leader = null;
                    }
                }
            }
        }
    } finally {
        if (leader == null && queue[0] != null)
            available.signal();
        lock.unlock();
    }
}


public final long awaitNanos(long nanosTimeout)
                throws InterruptedException {
            if (Thread.interrupted())   #增加一个等待节点，
                throw new InterruptedException();
            Node node = addConditionWaiter();
            int savedState = fullyRelease(node);
            final long deadline = System.nanoTime() + nanosTimeout;
            int interruptMode = 0;
            while (!isOnSyncQueue(node)) {
                if (nanosTimeout <= 0L) {
                    transferAfterCancelledWait(node);  #搬迁到AQS队列
                    break;
                }
                if (nanosTimeout >= spinForTimeoutThreshold)
                    LockSupport.parkNanos(this, nanosTimeout); #这个节点就park一段时间
                if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
                    break;
                nanosTimeout = deadline - System.nanoTime();
            }
            if (acquireQueued(node, savedState) && interruptMode != THROW_IE)
                interruptMode = REINTERRUPT;
            if (node.nextWaiter != null)
                unlinkCancelledWaiters();
            if (interruptMode != 0)
                reportInterruptAfterWait(interruptMode);
            return deadline - System.nanoTime();
        }

```





------------------------

https://cloud.tencent.com/developer/article/1110576

Future模式和Promise模式： Future 有两种模式：将来式和回调式。而回调式会出现回调地狱的问题，由此衍生出了 Promise 模式来解决这个问题。这才是 Future 模式和 Promise 模式的相关性。 

- Future将来式，FutrueTask的实现
- Future回调式，任务执行完通过回调去更新结果，这样主线程不会阻塞。

CompletableFuture 解决地狱回调







JAVA Future模式下有： ForkJoinTask、ScheduledFuture、CopletedFuture、RunnableFuture，这几种task都是作为任务加入到任务列表中的。

- ScheduledFutureTask被封装在ScheduledExecutorService这种线程池中
- ForkJoinTask和ForkJoinPool是设计耦合的
- FutureTask是完全独立的简化版的AQS
- CompletableFuture 是比Promise更高级的用法

--------------------------------

completableFuture:



创建Future：提供驱动，线程池驱动

````
public static CompletableFuture<Void>   runAsync(Runnable runnable)
public static CompletableFuture<Void>   runAsync(Runnable runnable, Executor executor)
public static <U> CompletableFuture<U>  supplyAsync(Supplier<U> supplier)
public static <U> CompletableFuture<U>  supplyAsync(Supplier<U> supplier, Executor executor)

````

获取结果

```

```

```

```

```

```

```

```

```

```



completableFuture的数据结构中有两个队列，一个waiter、一个completer，还有结果result





````
    abstract static class Async extends ForkJoinTask<Void>
        implements Runnable, AsynchronousCompletionTask {
        public final Void getRawResult() { return null; }
        public final void setRawResult(Void v) { }
        public final void run() { exec(); }
    }
````



初步的印象，cf中不带Asyn的，就是使用本线程执行该任务，待Asyn的，就是把任务丢到ForkJoin

Pool中执行。

completions存放的就是逻辑节点，各种either、or、and等组合逻辑节点。













































